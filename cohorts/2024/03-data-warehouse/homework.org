#+title: Module 3 Homework

First, download the [[https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page][2022 Green Taxi Trip Record Parquet files]] and save them inside ~./data/~.

#+begin_src python :results output
import os
import requests

data_directory = "./data"
os.makedirs(data_directory, exist_ok=True)

url_template = "https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2022-{}.parquet"
for xx in range(1, 13):
    url = url_template.format(str(xx).zfill(2))
    file_path = os.path.join(data_directory, f"green_tripdata_2022-{str(xx).zfill(2)}.parquet")
    response = requests.get(url)

    if response.status_code == 200:
        with open(file_path, 'wb') as file:
            file.write(response.content)
        print(f"File {file_path} downloaded successfully")
    else:
        print(f"Failed to download file {file_path}, status code: {response.status_code}")
#+end_src

#+RESULTS:
#+begin_example
File ./data/green_tripdata_2022-01.parquet downloaded successfully
File ./data/green_tripdata_2022-02.parquet downloaded successfully
File ./data/green_tripdata_2022-03.parquet downloaded successfully
File ./data/green_tripdata_2022-04.parquet downloaded successfully
File ./data/green_tripdata_2022-05.parquet downloaded successfully
File ./data/green_tripdata_2022-06.parquet downloaded successfully
File ./data/green_tripdata_2022-07.parquet downloaded successfully
File ./data/green_tripdata_2022-08.parquet downloaded successfully
File ./data/green_tripdata_2022-09.parquet downloaded successfully
File ./data/green_tripdata_2022-10.parquet downloaded successfully
File ./data/green_tripdata_2022-11.parquet downloaded successfully
File ./data/green_tripdata_2022-12.parquet downloaded successfully
#+end_example

Upload the files stored in ~./data/~ to Google Cloud Storage.

#+begin_src python :results output
import os
from google.cloud import storage

client = storage.Client.from_service_account_json('credentials.json')
bucket = client.get_bucket('module-3-kfghnfj')
data_dir = './data/'
for filename in os.listdir(data_dir):
    local_file_path = os.path.join(data_dir, filename)
    bucket.blob(filename).upload_from_filename(local_file_path)
    print(f'File {filename} uploaded to {bucket.name}')
#+end_src

#+RESULTS:
#+begin_example
File green_tripdata_2022-09.parquet uploaded to module-3-kfghnfj
File green_tripdata_2022-02.parquet uploaded to module-3-kfghnfj
File green_tripdata_2022-08.parquet uploaded to module-3-kfghnfj
File green_tripdata_2022-03.parquet uploaded to module-3-kfghnfj
File green_tripdata_2022-10.parquet uploaded to module-3-kfghnfj
File green_tripdata_2022-04.parquet uploaded to module-3-kfghnfj
File green_tripdata_2022-11.parquet uploaded to module-3-kfghnfj
File green_tripdata_2022-12.parquet uploaded to module-3-kfghnfj
File green_tripdata_2022-06.parquet uploaded to module-3-kfghnfj
File green_tripdata_2022-07.parquet uploaded to module-3-kfghnfj
File green_tripdata_2022-01.parquet uploaded to module-3-kfghnfj
File green_tripdata_2022-05.parquet uploaded to module-3-kfghnfj
#+end_example

In BigQuery, create an external table using the Parquet files in Google Cloud Storage.

#+begin_src sql
CREATE OR REPLACE EXTERNAL TABLE `terraform-module-1.nytaxi.green_tripdata_external`
OPTIONS (
  format = 'Parquet',
  uris = ['gs://module-3-kfghnfj/green_tripdata_2022-*.parquet']
);
#+end_src

In BigQuery, create a table without partitioning or clustering.

#+begin_src sql
CREATE OR REPLACE TABLE terraform-module-1.nytaxi.green_tripdata_no_partition AS
SELECT * FROM terraform-module-1.nytaxi.green_tripdata_external;
#+end_src

* Count records

What is count of records for the 2022 Green Taxi Data?

#+begin_src sql
SELECT COUNT(*) FROM terraform-module-1.nytaxi.green_tripdata_external
#+end_src

- [ ] 65,623,481
- [X] 840,402
- [ ] 1,936,423
- [ ] 253,647

* Count distinct =PULocationIDs=

Write a query to count the distinct number of PULocationIDs for the entire dataset on both the tables.
What is the estimated amount of data that will be read when this query is executed on the External Table and the Table?

#+begin_src sql
SELECT COUNT(DISTINCT PULocationID)
FROM terraform-module-1.nytaxi.green_tripdata_external
#+end_src

#+begin_comment
This information is displayed on the top right corner of any query tab.
#+end_comment

- [X] 0 MB for the External Table and 6.41MB for the Materialized Table
- [ ] 18.82 MB for the External Table and 47.60 MB for the Materialized Table
- [ ] 0 MB for the External Table and 0MB for the Materialized Table
- [ ] 2.14 MB for the External Table and 0MB for the Materialized Table

* Count records with =fare_amount= of 0

How many records have a =fare_amount= of 0?

#+begin_src sql
SELECT COUNT(*)
FROM terraform-module-1.nytaxi.green_tripdata_no_partition
WHERE fare_amount=0;
#+end_src

- [ ] 12,488
- [ ] 128,219
- [ ] 112
- [X] 1,622

* Best strategy for query

What is the best strategy to make an optimized table in Big Query if your query will always order the results by =PUlocationID= and filter based on =lpep_pickup_datetime=? (Create a new table with this strategy)

Partitioning helps pruning the data efficiently during query execution.
Clustering involves physically ordering the data within each partition based on a chosen column.

#+begin_src sql
CREATE OR REPLACE TABLE terraform-module-1.nytaxi.green_tripdata_partitioned_clustered
PARTITION BY DATE(lpep_pickup_datetime)
CLUSTER BY PULocationID AS
SELECT * FROM terraform-module-1.nytaxi.green_tripdata_external;
#+end_src

- [ ] Cluster on =lpep_pickup_datetime= Partition by =PUlocationID=
- [X] Partition by =lpep_pickup_datetime= Cluster on =PUlocationID=.
- [ ] Partition by =lpep_pickup_datetime= and Partition by =PUlocationID=
- [ ] Cluster on by =lpep_pickup_datetime= and Cluster on =PUlocationID=

* Distinct =PuLocationID= in date range

Write a query to retrieve the distinct =PULocationID= between =lpep_pickup_datetime= 06/01/2022 and 06/30/2022 (inclusive)

Use the materialized table you created earlier in your from clause and note the estimated bytes.
Now change the table in the from clause to the partitioned table you created for question 4 and note the estimated bytes processed.
What are these values?

Choose the answer which most closely matches.

#+begin_src sql
SELECT COUNT(DISTINCT PULocationID)
FROM terraform-module-1.nytaxi.green_tripdata_partitioned_clustered
WHERE DATE(lpep_pickup_datetime) BETWEEN '2022-06-01' AND '2022-06-30';
#+end_src

#+begin_src sql
SELECT COUNT(DISTINCT PULocationID)
FROM terraform-module-1.nytaxi.green_tripdata_no_partition
WHERE DATE(lpep_pickup_datetime) BETWEEN '2022-06-01' AND '2022-06-30';
#+end_src

- [ ] 22.82 MB for non-partitioned table and 647.87 MB for the partitioned table
- [X] 12.82 MB for non-partitioned table and 1.12 MB for the partitioned table
- [ ] 5.63 MB for non-partitioned table and 0 MB for the partitioned table
- [ ] 10.31 MB for non-partitioned table and 10.31 MB for the partitioned table

* Location of external table

Where is the data stored in the External Table you created?

- [ ] Big Query
- [ ] GCP Bucket
- [ ] Big Table
- [ ] Container Registry

* Clustering in Big Query

It is best practice in Big Query to always cluster your data:

- [ ] True
- [ ] False

* Bonus

No Points: Write a =SELECT count(*)= query FROM the materialized table
you created. How many bytes does it estimate will be read? Why?

* Submitting the solutions

- Form for submitting: https://courses.datatalks.club/de-zoomcamp-2024/homework/hw3
